{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import GPT2Model\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT2CIFAR10(nn.Module):\n",
    "    def __init__(self, patch_size=4, num_classes=10, freeze_gpt2=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Load pretrained GPT2\n",
    "        self.gpt2 = GPT2Model.from_pretrained('gpt2')\n",
    "        self.hidden_size = self.gpt2.config.hidden_size  # 768 for base GPT2\n",
    "        \n",
    "        # CIFAR-10 characteristics\n",
    "        self.image_size = 32\n",
    "        self.patch_size = patch_size\n",
    "        self.num_patches = (self.image_size // patch_size) ** 2\n",
    "        \n",
    "        # Patch embedding layer: from image patches to GPT2 hidden size\n",
    "        self.patch_embedding = nn.Conv2d(3, self.hidden_size, \n",
    "                                       kernel_size=patch_size, \n",
    "                                       stride=patch_size)\n",
    "        \n",
    "        # Classification head\n",
    "        self.classifier = nn.Linear(self.hidden_size, num_classes)\n",
    "        \n",
    "        if freeze_gpt2:\n",
    "            # Freeze GPT2 parameters except LayerNorm and positional embeddings\n",
    "            for name, param in self.gpt2.named_parameters():\n",
    "                if 'ln' in name or 'wpe' in name:\n",
    "                    param.requires_grad = True\n",
    "                else:\n",
    "                    param.requires_grad = False\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        # Convert image to patches\n",
    "        # Shape: (batch_size, hidden_size, h', w')\n",
    "        patches = self.patch_embedding(x)\n",
    "        \n",
    "        # Reshape and transpose for GPT2\n",
    "        # Shape: (batch_size, num_patches, hidden_size)\n",
    "        patches = rearrange(patches, 'b d h w -> b (h w) d')\n",
    "        \n",
    "        # Pass through GPT2 and get last hidden state\n",
    "        outputs = self.gpt2(inputs_embeds=patches)\n",
    "        hidden_states = outputs.last_hidden_state\n",
    "        \n",
    "        # Use the last token's representation for classification\n",
    "        cls_representation = hidden_states[:, -1]\n",
    "        \n",
    "        # Classify\n",
    "        logits = self.classifier(cls_representation)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10Trainer:\n",
    "    def __init__(self, model, train_loader, val_loader, \n",
    "                 criterion, optimizer, device, config):\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.device = device\n",
    "        self.config = config\n",
    "        \n",
    "        # Initialize metrics tracking\n",
    "        self.train_losses = []\n",
    "        self.train_accuracies = []\n",
    "        self.val_losses = []\n",
    "        self.val_accuracies = []\n",
    "        \n",
    "        # Initialize best validation accuracy for model saving\n",
    "        self.best_val_acc = 0.0\n",
    "        \n",
    "    def train_epoch(self):\n",
    "        self.model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        pbar = tqdm(self.train_loader, desc='Training')\n",
    "        for batch_idx, (images, labels) in enumerate(pbar):\n",
    "            images, labels = images.to(self.device), labels.to(self.device)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(images)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            pbar.set_postfix({\n",
    "                'loss': running_loss/(batch_idx+1),\n",
    "                'acc': 100.*correct/total\n",
    "            })\n",
    "        \n",
    "        epoch_loss = running_loss / len(self.train_loader)\n",
    "        epoch_acc = 100. * correct / total\n",
    "        return epoch_loss, epoch_acc\n",
    "    \n",
    "    def validate(self):\n",
    "        self.model.eval()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(self.val_loader, desc='Validation'):\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                \n",
    "                outputs = self.model(images)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        val_loss = running_loss / len(self.val_loader)\n",
    "        val_acc = 100. * correct / total\n",
    "        return val_loss, val_acc\n",
    "    \n",
    "    def train(self, num_epochs):\n",
    "        # Initialize wandb\n",
    "        wandb.init(\n",
    "            project=\"gpt2-cifar10\", \n",
    "            config=self.config,\n",
    "            name=f'{self.config[\"learning_rate\"]}lr_{self.config[\"batch_size\"]}bs_{self.config[\"patch_size\"]}patch'\n",
    "        )\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            # Training phase\n",
    "            train_loss, train_acc = self.train_epoch()\n",
    "            self.train_losses.append(train_loss)\n",
    "            self.train_accuracies.append(train_acc)\n",
    "            \n",
    "            # Validation phase\n",
    "            val_loss, val_acc = self.validate()\n",
    "            self.val_losses.append(val_loss)\n",
    "            self.val_accuracies.append(val_acc)\n",
    "            \n",
    "            # Log metrics\n",
    "            wandb.log({\n",
    "                \"epoch\": epoch,\n",
    "                \"train_loss\": train_loss,\n",
    "                \"train_acc\": train_acc,\n",
    "                \"val_loss\": val_loss,\n",
    "                \"val_acc\": val_acc,\n",
    "            })\n",
    "            \n",
    "            # Save best model\n",
    "            if val_acc > self.best_val_acc:\n",
    "                self.best_val_acc = val_acc\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': self.model.state_dict(),\n",
    "                    'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "                    'val_acc': val_acc,\n",
    "                }, 'best_model.pth')\n",
    "                wandb.save('best_model.pth')\n",
    "            \n",
    "            print(f'Epoch: {epoch+1}/{num_epochs}')\n",
    "            print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
    "            print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "            print('-' * 60)\n",
    "        \n",
    "        wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [00:07<00:00, 23.3MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# Load CIFAR10\n",
    "trainset = datasets.CIFAR10(root='./data', train=True,\n",
    "                          download=True, transform=transform_train)\n",
    "valset = datasets.CIFAR10(root='./data', train=False,\n",
    "                         download=True, transform=transform_val)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "valloader = DataLoader(valset, batch_size=128, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: Currently logged in as: dporres (dporres-computer-vision-center). Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Windows\\Documents\\CVC\\repos\\seeing-language\\notebooks\\wandb\\run-20241111_230849-kjps7qnm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dporres-computer-vision-center/gpt2-cifar10/runs/kjps7qnm' target=\"_blank\">morning-cherry-1</a></strong> to <a href='https://wandb.ai/dporres-computer-vision-center/gpt2-cifar10' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dporres-computer-vision-center/gpt2-cifar10' target=\"_blank\">https://wandb.ai/dporres-computer-vision-center/gpt2-cifar10</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dporres-computer-vision-center/gpt2-cifar10/runs/kjps7qnm' target=\"_blank\">https://wandb.ai/dporres-computer-vision-center/gpt2-cifar10/runs/kjps7qnm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [16:33<00:00,  2.54s/it, loss=2.32, acc=14.6]  \n",
      "Validation: 100%|██████████| 79/79 [00:17<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50\n",
      "Train Loss: 2.3167, Train Acc: 14.61%\n",
      "Val Loss: 2.1477, Val Acc: 21.83%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:30<00:00,  2.60it/s, loss=2.19, acc=19.9]\n",
      "Validation: 100%|██████████| 79/79 [00:16<00:00,  4.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/50\n",
      "Train Loss: 2.1854, Train Acc: 19.93%\n",
      "Val Loss: 2.0410, Val Acc: 24.67%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:28<00:00,  2.63it/s, loss=2.02, acc=26.1]\n",
      "Validation: 100%|██████████| 79/79 [00:16<00:00,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/50\n",
      "Train Loss: 2.0153, Train Acc: 26.10%\n",
      "Val Loss: 1.9293, Val Acc: 29.97%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:31<00:00,  2.58it/s, loss=1.89, acc=30.7]\n",
      "Validation: 100%|██████████| 79/79 [00:16<00:00,  4.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/50\n",
      "Train Loss: 1.8900, Train Acc: 30.66%\n",
      "Val Loss: 1.8495, Val Acc: 34.01%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:29<00:00,  2.61it/s, loss=1.79, acc=34.1]\n",
      "Validation: 100%|██████████| 79/79 [00:16<00:00,  4.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/50\n",
      "Train Loss: 1.7879, Train Acc: 34.12%\n",
      "Val Loss: 1.8029, Val Acc: 35.88%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:29<00:00,  2.61it/s, loss=1.71, acc=37.1]\n",
      "Validation: 100%|██████████| 79/79 [00:17<00:00,  4.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/50\n",
      "Train Loss: 1.7066, Train Acc: 37.05%\n",
      "Val Loss: 1.6674, Val Acc: 39.77%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:31<00:00,  2.58it/s, loss=1.65, acc=39.1]\n",
      "Validation: 100%|██████████| 79/79 [00:17<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/50\n",
      "Train Loss: 1.6483, Train Acc: 39.07%\n",
      "Val Loss: 1.6357, Val Acc: 40.89%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:37<00:00,  2.48it/s, loss=1.61, acc=40.9]\n",
      "Validation: 100%|██████████| 79/79 [00:17<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/50\n",
      "Train Loss: 1.6056, Train Acc: 40.89%\n",
      "Val Loss: 1.5743, Val Acc: 43.42%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:32<00:00,  2.56it/s, loss=1.57, acc=42.5]\n",
      "Validation: 100%|██████████| 79/79 [00:16<00:00,  4.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/50\n",
      "Train Loss: 1.5651, Train Acc: 42.47%\n",
      "Val Loss: 1.4955, Val Acc: 45.68%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:30<00:00,  2.61it/s, loss=1.53, acc=44]  \n",
      "Validation: 100%|██████████| 79/79 [00:17<00:00,  4.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/50\n",
      "Train Loss: 1.5282, Train Acc: 44.05%\n",
      "Val Loss: 1.4660, Val Acc: 46.96%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:30<00:00,  2.60it/s, loss=1.5, acc=45.5] \n",
      "Validation: 100%|██████████| 79/79 [00:16<00:00,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11/50\n",
      "Train Loss: 1.4956, Train Acc: 45.50%\n",
      "Val Loss: 1.4415, Val Acc: 47.79%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:30<00:00,  2.61it/s, loss=1.46, acc=46.8]\n",
      "Validation: 100%|██████████| 79/79 [00:17<00:00,  4.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12/50\n",
      "Train Loss: 1.4649, Train Acc: 46.79%\n",
      "Val Loss: 1.3951, Val Acc: 49.60%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:30<00:00,  2.60it/s, loss=1.44, acc=47.5]\n",
      "Validation: 100%|██████████| 79/79 [00:16<00:00,  4.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13/50\n",
      "Train Loss: 1.4435, Train Acc: 47.53%\n",
      "Val Loss: 1.3835, Val Acc: 50.44%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:30<00:00,  2.60it/s, loss=1.42, acc=48.3]\n",
      "Validation: 100%|██████████| 79/79 [00:17<00:00,  4.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14/50\n",
      "Train Loss: 1.4197, Train Acc: 48.31%\n",
      "Val Loss: 1.3608, Val Acc: 51.01%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:33<00:00,  2.55it/s, loss=1.4, acc=49]  \n",
      "Validation: 100%|██████████| 79/79 [00:17<00:00,  4.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15/50\n",
      "Train Loss: 1.4003, Train Acc: 49.04%\n",
      "Val Loss: 1.3625, Val Acc: 50.51%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:32<00:00,  2.56it/s, loss=1.38, acc=49.7]\n",
      "Validation: 100%|██████████| 79/79 [00:18<00:00,  4.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16/50\n",
      "Train Loss: 1.3819, Train Acc: 49.74%\n",
      "Val Loss: 1.3254, Val Acc: 52.31%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:39<00:00,  2.46it/s, loss=1.37, acc=50.3]\n",
      "Validation: 100%|██████████| 79/79 [00:18<00:00,  4.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17/50\n",
      "Train Loss: 1.3669, Train Acc: 50.31%\n",
      "Val Loss: 1.3098, Val Acc: 52.45%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:40<00:00,  2.44it/s, loss=1.35, acc=51.4]\n",
      "Validation: 100%|██████████| 79/79 [00:18<00:00,  4.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18/50\n",
      "Train Loss: 1.3476, Train Acc: 51.40%\n",
      "Val Loss: 1.2748, Val Acc: 54.12%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:39<00:00,  2.46it/s, loss=1.33, acc=51.6]\n",
      "Validation: 100%|██████████| 79/79 [00:17<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19/50\n",
      "Train Loss: 1.3309, Train Acc: 51.57%\n",
      "Val Loss: 1.2554, Val Acc: 55.02%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:36<00:00,  2.50it/s, loss=1.32, acc=52.1]\n",
      "Validation: 100%|██████████| 79/79 [00:17<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20/50\n",
      "Train Loss: 1.3244, Train Acc: 52.12%\n",
      "Val Loss: 1.2419, Val Acc: 55.39%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:33<00:00,  2.54it/s, loss=1.31, acc=52.7]\n",
      "Validation: 100%|██████████| 79/79 [00:17<00:00,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21/50\n",
      "Train Loss: 1.3076, Train Acc: 52.65%\n",
      "Val Loss: 1.2695, Val Acc: 55.23%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:28<00:00,  2.63it/s, loss=1.3, acc=53]   \n",
      "Validation: 100%|██████████| 79/79 [00:17<00:00,  4.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22/50\n",
      "Train Loss: 1.3011, Train Acc: 53.00%\n",
      "Val Loss: 1.2421, Val Acc: 55.26%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:33<00:00,  2.54it/s, loss=1.29, acc=53.5]\n",
      "Validation: 100%|██████████| 79/79 [00:17<00:00,  4.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23/50\n",
      "Train Loss: 1.2907, Train Acc: 53.53%\n",
      "Val Loss: 1.2274, Val Acc: 56.30%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:33<00:00,  2.55it/s, loss=1.28, acc=53.9]\n",
      "Validation: 100%|██████████| 79/79 [00:17<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24/50\n",
      "Train Loss: 1.2780, Train Acc: 53.86%\n",
      "Val Loss: 1.2272, Val Acc: 56.01%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:36<00:00,  2.50it/s, loss=1.27, acc=54.1]\n",
      "Validation: 100%|██████████| 79/79 [00:17<00:00,  4.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25/50\n",
      "Train Loss: 1.2681, Train Acc: 54.10%\n",
      "Val Loss: 1.2306, Val Acc: 56.01%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:32<00:00,  2.56it/s, loss=1.26, acc=54.3]\n",
      "Validation: 100%|██████████| 79/79 [00:16<00:00,  4.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26/50\n",
      "Train Loss: 1.2618, Train Acc: 54.33%\n",
      "Val Loss: 1.1964, Val Acc: 57.28%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:22<00:00,  2.75it/s, loss=1.25, acc=54.8]\n",
      "Validation: 100%|██████████| 79/79 [00:15<00:00,  5.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27/50\n",
      "Train Loss: 1.2487, Train Acc: 54.78%\n",
      "Val Loss: 1.1720, Val Acc: 58.52%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:17<00:00,  2.85it/s, loss=1.24, acc=54.9]\n",
      "Validation: 100%|██████████| 79/79 [00:15<00:00,  4.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28/50\n",
      "Train Loss: 1.2433, Train Acc: 54.92%\n",
      "Val Loss: 1.1745, Val Acc: 58.54%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:17<00:00,  2.85it/s, loss=1.24, acc=55.2]\n",
      "Validation: 100%|██████████| 79/79 [00:16<00:00,  4.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29/50\n",
      "Train Loss: 1.2400, Train Acc: 55.21%\n",
      "Val Loss: 1.1722, Val Acc: 58.52%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:23<00:00,  2.73it/s, loss=1.23, acc=55.6]\n",
      "Validation: 100%|██████████| 79/79 [00:16<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30/50\n",
      "Train Loss: 1.2276, Train Acc: 55.62%\n",
      "Val Loss: 1.1777, Val Acc: 58.37%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:29<00:00,  2.61it/s, loss=1.22, acc=56.2]\n",
      "Validation: 100%|██████████| 79/79 [00:17<00:00,  4.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31/50\n",
      "Train Loss: 1.2228, Train Acc: 56.17%\n",
      "Val Loss: 1.1646, Val Acc: 58.45%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:28<00:00,  2.63it/s, loss=1.22, acc=56.1]\n",
      "Validation: 100%|██████████| 79/79 [00:16<00:00,  4.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32/50\n",
      "Train Loss: 1.2207, Train Acc: 56.12%\n",
      "Val Loss: 1.1711, Val Acc: 58.58%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:34<00:00,  2.53it/s, loss=1.21, acc=56.2]\n",
      "Validation: 100%|██████████| 79/79 [00:16<00:00,  4.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33/50\n",
      "Train Loss: 1.2107, Train Acc: 56.22%\n",
      "Val Loss: 1.1445, Val Acc: 59.19%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:22<00:00,  2.75it/s, loss=1.21, acc=56.5]\n",
      "Validation: 100%|██████████| 79/79 [00:15<00:00,  5.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34/50\n",
      "Train Loss: 1.2057, Train Acc: 56.51%\n",
      "Val Loss: 1.1477, Val Acc: 59.54%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:23<00:00,  2.72it/s, loss=1.2, acc=56.8] \n",
      "Validation: 100%|██████████| 79/79 [00:17<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35/50\n",
      "Train Loss: 1.1992, Train Acc: 56.78%\n",
      "Val Loss: 1.1338, Val Acc: 59.91%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:26<00:00,  2.66it/s, loss=1.19, acc=56.8]\n",
      "Validation: 100%|██████████| 79/79 [00:16<00:00,  4.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36/50\n",
      "Train Loss: 1.1930, Train Acc: 56.80%\n",
      "Val Loss: 1.1357, Val Acc: 60.02%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:30<00:00,  2.61it/s, loss=1.18, acc=57.5]\n",
      "Validation: 100%|██████████| 79/79 [00:16<00:00,  4.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37/50\n",
      "Train Loss: 1.1803, Train Acc: 57.48%\n",
      "Val Loss: 1.1290, Val Acc: 60.36%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:28<00:00,  2.64it/s, loss=1.18, acc=57.5]\n",
      "Validation: 100%|██████████| 79/79 [00:17<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38/50\n",
      "Train Loss: 1.1803, Train Acc: 57.53%\n",
      "Val Loss: 1.1279, Val Acc: 59.90%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:33<00:00,  2.56it/s, loss=1.18, acc=57.9]\n",
      "Validation: 100%|██████████| 79/79 [00:16<00:00,  4.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39/50\n",
      "Train Loss: 1.1773, Train Acc: 57.92%\n",
      "Val Loss: 1.1152, Val Acc: 60.69%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:29<00:00,  2.61it/s, loss=1.17, acc=58]  \n",
      "Validation: 100%|██████████| 79/79 [00:17<00:00,  4.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40/50\n",
      "Train Loss: 1.1666, Train Acc: 58.04%\n",
      "Val Loss: 1.0982, Val Acc: 61.26%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:28<00:00,  2.63it/s, loss=1.17, acc=58.1]\n",
      "Validation: 100%|██████████| 79/79 [00:16<00:00,  4.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41/50\n",
      "Train Loss: 1.1675, Train Acc: 58.08%\n",
      "Val Loss: 1.1031, Val Acc: 60.58%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:29<00:00,  2.61it/s, loss=1.16, acc=58]  \n",
      "Validation: 100%|██████████| 79/79 [00:17<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42/50\n",
      "Train Loss: 1.1623, Train Acc: 58.01%\n",
      "Val Loss: 1.0878, Val Acc: 61.49%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:27<00:00,  2.65it/s, loss=1.16, acc=58.1]\n",
      "Validation: 100%|██████████| 79/79 [00:16<00:00,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43/50\n",
      "Train Loss: 1.1594, Train Acc: 58.14%\n",
      "Val Loss: 1.0954, Val Acc: 61.35%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:27<00:00,  2.65it/s, loss=1.15, acc=58.6]\n",
      "Validation: 100%|██████████| 79/79 [00:16<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44/50\n",
      "Train Loss: 1.1518, Train Acc: 58.55%\n",
      "Val Loss: 1.0833, Val Acc: 61.50%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:28<00:00,  2.63it/s, loss=1.14, acc=58.9]\n",
      "Validation: 100%|██████████| 79/79 [00:16<00:00,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45/50\n",
      "Train Loss: 1.1425, Train Acc: 58.87%\n",
      "Val Loss: 1.0991, Val Acc: 60.89%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:28<00:00,  2.63it/s, loss=1.14, acc=58.8]\n",
      "Validation: 100%|██████████| 79/79 [00:16<00:00,  4.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46/50\n",
      "Train Loss: 1.1433, Train Acc: 58.78%\n",
      "Val Loss: 1.0851, Val Acc: 61.50%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:31<00:00,  2.58it/s, loss=1.14, acc=59.2]\n",
      "Validation: 100%|██████████| 79/79 [00:17<00:00,  4.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47/50\n",
      "Train Loss: 1.1364, Train Acc: 59.17%\n",
      "Val Loss: 1.0792, Val Acc: 61.61%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:36<00:00,  2.50it/s, loss=1.13, acc=59.5]\n",
      "Validation: 100%|██████████| 79/79 [00:18<00:00,  4.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48/50\n",
      "Train Loss: 1.1299, Train Acc: 59.46%\n",
      "Val Loss: 1.0756, Val Acc: 61.87%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:37<00:00,  2.49it/s, loss=1.13, acc=59.5]\n",
      "Validation: 100%|██████████| 79/79 [00:17<00:00,  4.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49/50\n",
      "Train Loss: 1.1275, Train Acc: 59.52%\n",
      "Val Loss: 1.0723, Val Acc: 61.98%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:29<00:00,  2.61it/s, loss=1.12, acc=59.7]\n",
      "Validation: 100%|██████████| 79/79 [00:16<00:00,  4.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50/50\n",
      "Train Loss: 1.1245, Train Acc: 59.68%\n",
      "Val Loss: 1.0737, Val Acc: 62.22%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68f9f4d0f28b4b7e94b63b3f7a9cdaf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='10.442 MB of 353.161 MB uploaded\\r'), FloatProgress(value=0.029568185148566333, ma…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇███</td></tr><tr><td>train_acc</td><td>▁▂▃▃▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██████████████</td></tr><tr><td>train_loss</td><td>█▇▆▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▁▂▃▃▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇██████████████</td></tr><tr><td>val_loss</td><td>█▇▇▆▆▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>train_acc</td><td>59.676</td></tr><tr><td>train_loss</td><td>1.12449</td></tr><tr><td>val_acc</td><td>62.22</td></tr><tr><td>val_loss</td><td>1.0737</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">morning-cherry-1</strong> at: <a href='https://wandb.ai/dporres-computer-vision-center/gpt2-cifar10/runs/kjps7qnm' target=\"_blank\">https://wandb.ai/dporres-computer-vision-center/gpt2-cifar10/runs/kjps7qnm</a><br/> View project at: <a href='https://wandb.ai/dporres-computer-vision-center/gpt2-cifar10' target=\"_blank\">https://wandb.ai/dporres-computer-vision-center/gpt2-cifar10</a><br/>Synced 4 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241111_230849-kjps7qnm\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Configuration\n",
    "config = {\n",
    "    'patch_size': 4,\n",
    "    'num_classes': 10,\n",
    "    'batch_size': 16,\n",
    "    'learning_rate': 1e-3,\n",
    "    'num_epochs': 100,\n",
    "}\n",
    "\n",
    "# Initialize model and training components\n",
    "model = GPT2CIFAR10(patch_size=config['patch_size'], \n",
    "                    num_classes=config['num_classes'])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = CIFAR10Trainer(\n",
    "    model=model,\n",
    "    train_loader=trainloader,\n",
    "    val_loader=valloader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# Train model\n",
    "trainer.train(num_epochs=config['num_epochs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Windows\\Documents\\CVC\\repos\\seeing-language\\notebooks\\01_gpt2_cifar10.ipynb Cell 7\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Windows/Documents/CVC/repos/seeing-language/notebooks/01_gpt2_cifar10.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Windows/Documents/CVC/repos/seeing-language/notebooks/01_gpt2_cifar10.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Windows/Documents/CVC/repos/seeing-language/notebooks/01_gpt2_cifar10.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Windows/Documents/CVC/repos/seeing-language/notebooks/01_gpt2_cifar10.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m \u001b[39mimport\u001b[39;00m transforms\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Windows/Documents/CVC/repos/seeing-language/notebooks/01_gpt2_cifar10.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT2Visualizer:\n",
    "    def __init__(self, model, device, class_names):\n",
    "        self.model = model.to(device)\n",
    "        self.device = device\n",
    "        self.class_names = class_names\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Save reference to GPT2 attention\n",
    "        self.attention_maps = []\n",
    "        \n",
    "        # Register hook to get attention weights\n",
    "        def attention_hook(module, input, output):\n",
    "            # Get attention weights from output tuple\n",
    "            # Shape: (batch_size, num_heads, sequence_length, sequence_length)\n",
    "            self.attention_maps.append(output[0].detach())\n",
    "        \n",
    "        # Register hooks for all attention blocks\n",
    "        for name, module in model.named_modules():\n",
    "            if \"attn\" in name and \"block\" in name:\n",
    "                module.register_forward_hook(attention_hook)\n",
    "        \n",
    "        # Standard CIFAR-10 normalization\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), \n",
    "                               (0.2023, 0.1994, 0.2010))\n",
    "        ])\n",
    "    \n",
    "    def predict_and_visualize(self, images, true_labels=None, num_images=5):\n",
    "        \"\"\"\n",
    "        Visualize predictions and attention maps for a batch of images\n",
    "        \n",
    "        Args:\n",
    "            images: List of PIL images or tensor of shape (N, C, H, W)\n",
    "            true_labels: Optional list of true labels\n",
    "            num_images: Number of images to visualize\n",
    "        \"\"\"\n",
    "        # Clear previous attention maps\n",
    "        self.attention_maps = []\n",
    "        \n",
    "        # Prepare images if they're PIL\n",
    "        if not torch.is_tensor(images):\n",
    "            tensors = []\n",
    "            for img in images:\n",
    "                tensors.append(self.transform(img))\n",
    "            images = torch.stack(tensors)\n",
    "        \n",
    "        # Move to device\n",
    "        images = images.to(self.device)\n",
    "        \n",
    "        # Get predictions\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(images[:num_images])\n",
    "            predictions = outputs.argmax(dim=1)\n",
    "        \n",
    "        # Get attention weights (average over heads and layers)\n",
    "        # Shape: (batch_size, num_patches, num_patches)\n",
    "        avg_attention = torch.mean(torch.stack([\n",
    "            torch.mean(attention, dim=1) \n",
    "            for attention in self.attention_maps\n",
    "        ]), dim=0)\n",
    "        \n",
    "        # Create figure\n",
    "        num_cols = 3  # image, attention, patch attention\n",
    "        fig = plt.figure(figsize=(15, 5 * num_images))\n",
    "        \n",
    "        for idx in range(num_images):\n",
    "            # Original image with prediction\n",
    "            ax1 = plt.subplot(num_images, num_cols, idx * num_cols + 1)\n",
    "            img = images[idx].cpu()\n",
    "            img = img * torch.tensor([0.2023, 0.1994, 0.2010]).view(3, 1, 1) + \\\n",
    "                  torch.tensor([0.4914, 0.4822, 0.4465]).view(3, 1, 1)\n",
    "            plt.imshow(img.permute(1, 2, 0).clip(0, 1))\n",
    "            \n",
    "            # Set title color based on prediction\n",
    "            pred_class = self.class_names[predictions[idx]]\n",
    "            if true_labels is not None:\n",
    "                color = 'green' if predictions[idx] == true_labels[idx] else 'red'\n",
    "                title = f'Pred: {pred_class}\\nTrue: {self.class_names[true_labels[idx]]}'\n",
    "            else:\n",
    "                color = 'black'\n",
    "                title = f'Pred: {pred_class}'\n",
    "            \n",
    "            ax1.set_title(title, color=color)\n",
    "            plt.axis('off')\n",
    "            \n",
    "            # Attention heatmap\n",
    "            ax2 = plt.subplot(num_images, num_cols, idx * num_cols + 2)\n",
    "            attention_map = avg_attention[idx].cpu()\n",
    "            sns.heatmap(attention_map, cmap='viridis')\n",
    "            ax2.set_title('Average Self-Attention')\n",
    "            \n",
    "            # Patch-wise attention visualization\n",
    "            ax3 = plt.subplot(num_images, num_cols, idx * num_cols + 3)\n",
    "            # Get attention for the classification token (last token)\n",
    "            patch_attention = attention_map[-1, :-1].reshape(4, 4)  # for 8x8 patches\n",
    "            sns.heatmap(patch_attention, cmap='viridis')\n",
    "            ax3.set_title('Patch Attention Weights')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "checkpoint = torch.load('C:\\\\Users\\\\Windows\\\\Documents\\\\CVC\\\\repos\\seeing-language\\\\notebooks\\wandb\\\\run-20241111_230849-kjps7qnm\\\\files\\\\best_model.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# CIFAR-10 class names\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# Initialize visualizer\n",
    "visualizer = GPT2Visualizer(model, device, class_names)\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# Load CIFAR10\n",
    "valset = datasets.CIFAR10(root='./data', train=False,\n",
    "                         download=True, transform=transform_val)\n",
    "\n",
    "valloader = DataLoader(valset, batch_size=128, shuffle=False, num_workers=2)\n",
    "\n",
    "# Get some test images\n",
    "dataiter = iter(valloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Visualize predictions and attention\n",
    "fig = visualizer.predict_and_visualize(images[:5], labels[:5])\n",
    "plt.show()\n",
    "\n",
    "# To save the figure\n",
    "# fig.savefig('predictions_attention.png', bbox_inches='tight', dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uce",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
